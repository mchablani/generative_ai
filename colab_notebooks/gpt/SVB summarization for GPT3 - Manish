{"cells":[{"cell_type":"markdown","source":["Mount colab"],"metadata":{"id":"RIBYK_IywoMM"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XadOLcPPwsaI","executionInfo":{"status":"ok","timestamp":1679085712152,"user_tz":420,"elapsed":30701,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}},"outputId":"fd8a8dde-f5bb-484b-9c48-d374295089fb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"JwdhZA9KPRRP"},"source":["## 1. Download text corpus\n","\n","All texts are downloaded from [this reference doc](https://docs.google.com/document/d/1SbxPxOftU3vH5Q3aZBGWZYwxmXM2VDsJZcRj9jO8Rg8/edit). In progress: \n","\n","\n","*   Figuring out the best format to scrape tweets and their replies (Tweepy? SNscrape? Beautiful Soup?)\n","*   Transcribing podcasts and videos (whisper + pyannote format, [sample colab here](https://https://colab.research.google.com/drive/1TBe7zSfWYrT6rx65Tn06aZALkXUc7BOi#scrollTo=JwdhZA9KPRRP&line=7&uniqifier=1)). High RAM use.\n","\n","This also includes future investigations:\n","\n","*   Understanding if we can direct the LLM to a url versus have to download the whole article (HTML or rtf format)\n","*   Understand if there is quality difference in responses if use html (messy) versus cleaned up text\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8s2D2f7BQM_E"},"source":["# 2. Install our dependencies and define our functions\n","\n","Install GPT Index and Langchain. We'll also define the functions that we'll use later to construct our index and query it.\n","\n","First, let's install our dependencies."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hwEIqQd3aL0r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679085730706,"user_tz":420,"elapsed":18557,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}},"outputId":"9b12d0c3-76ac-4f4d-b46d-9ec3b88183b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gpt-index\n","  Downloading gpt_index-0.4.29-py3-none-any.whl (248 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.9/248.9 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gpt-index) (1.4.4)\n","Collecting langchain\n","  Downloading langchain-0.0.115-py3-none-any.whl (404 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.3/404.3 KB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openai>=0.26.4\n","  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.9/dist-packages (from gpt-index) (8.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gpt-index) (1.22.4)\n","Collecting tiktoken\n","  Downloading tiktoken-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dataclasses-json\n","  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->gpt-index) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai>=0.26.4->gpt-index) (4.65.0)\n","Collecting marshmallow-enum<2.0.0,>=1.5.1\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting typing-inspect>=0.4.0\n","  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n","Collecting marshmallow<4.0.0,>=3.3.0\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->gpt-index) (1.10.6)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain->gpt-index) (6.0)\n","Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain->gpt-index) (1.4.46)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gpt-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gpt-index) (2022.7.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->gpt-index) (2022.10.31)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->gpt-index) (22.2.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai>=0.26.4->gpt-index) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt-index) (23.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain->gpt-index) (4.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->gpt-index) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai>=0.26.4->gpt-index) (3.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain->gpt-index) (2.0.2)\n","Collecting mypy-extensions>=0.3.0\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, tiktoken, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, openai, langchain, gpt-index\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 gpt-index-0.4.29 langchain-0.0.115 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.2 tiktoken-0.3.2 typing-inspect-0.8.0 yarl-1.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.115)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n","Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.6)\n","Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.46)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n","Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n","Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"]}],"source":["\n","!pip install gpt-index\n","!pip install langchain"]},{"cell_type":"markdown","metadata":{"id":"qiQSJU9baR4u"},"source":["Define the functions we're going to use later in order to construct our index and query it. Future work entails:\n","\n","\n","*   Understanding if adjusting maximum input size will impact quality of responses\n","*   Create function to estimate the cost of the embedding beforehand\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"J8qiIErLLiRX","executionInfo":{"status":"ok","timestamp":1679088233739,"user_tz":420,"elapsed":335,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}}},"outputs":[],"source":["from gpt_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n","from langchain import OpenAI\n","import sys\n","import os\n","from IPython.display import Markdown, display\n","\n","def construct_index(directory_path):\n","    # set maximum input size\n","    max_input_size = 4096\n","    # set number of output tokens\n","    num_outputs = 256\n","    # set maximum chunk overlap\n","    max_chunk_overlap = 20\n","    # set chunk size limit\n","    chunk_size_limit = 600\n","\n","    # define LLM\n","    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n","    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n"," \n","    documents = SimpleDirectoryReader(directory_path).load_data()\n","    \n","    index = GPTSimpleVectorIndex(\n","        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n","    )\n","\n","    index.save_to_disk('gdrive/MyDrive/expa/svb_gpt/index.json')\n","\n","    return index\n","\n","def ask_svb():\n","    index = GPTSimpleVectorIndex.load_from_disk('gdrive/MyDrive/expa/svb_gpt/index.json')\n","    while True: \n","        query = input(\"What questions do you have about the SVB meltdown? \")\n","        response = index.query(query, response_mode=\"compact\")\n","        display(Markdown(f\"SVB Bot says: <b>{response.response}</b>\"))\n","  "]},{"cell_type":"markdown","metadata":{"id":"pftgPf5rQqox"},"source":["# 3. Set OpenAI API Key\n","In order to run this notebook you'll need an API key from OpenAI ([Sign up here](https://platform.openai.com/overview)).\n","\n","Then run the code below and paste it into the text input.\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TZ6WSBhxQLbK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679086420841,"user_tz":420,"elapsed":5746,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}},"outputId":"eb6f441f-7594-4a98-8850-6305489b9283"},"outputs":[{"name":"stdout","output_type":"stream","text":["Paste your OpenAI API key here and hit enter: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\n"]}],"source":["os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI API key here and hit enter:\")"]},{"cell_type":"markdown","metadata":{"id":"gyIIBFSkRbVU"},"source":["# 4. Construct Index\n","\n","Now we're going to construct our index. This will take every file in the folder 'SVB Research', split it into chunks, and embed it with OpenAI's embeddings API.\n","\n","**Important Note:** This step costs money.\n"]},{"cell_type":"code","source":["%ls gdrive/MyDrive/expa/svb_gpt/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2N7A5RszdVy","executionInfo":{"status":"ok","timestamp":1679088244830,"user_tz":420,"elapsed":342,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}},"outputId":"ccd9403d-8050-4671-c873-5f7cea7118a0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;36m'SVB research'\u001b[0m@\n"]}]},{"cell_type":"markdown","source":["Install PyPDF2 to accommodate for the one pdf we have."],"metadata":{"id":"FEsrG2i18Fzy"}},{"cell_type":"code","source":["!pip install PyPDF2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wm0rhvwt7_Aw","executionInfo":{"status":"ok","timestamp":1679088254175,"user_tz":420,"elapsed":3663,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}},"outputId":"a747ece8-e459-4577-cbf6-85bc1a775c67"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.9/dist-packages (3.0.1)\n","Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":187094,"status":"ok","timestamp":1679088441602,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"},"user_tz":420},"id":"BqCTqL9jRiLm","outputId":"f4562087-8503-4371-d28a-46056bbf82f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gpt_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7fc78acd3640>"]},"metadata":{},"execution_count":16}],"source":["construct_index('gdrive/MyDrive/expa/svb_gpt/SVB research/')"]},{"cell_type":"markdown","metadata":{"id":"4gHdfdtsSGEW"},"source":["# 5. Ask Questions!\n","\n","Now we'll run the \"ask_svb\" function we defined above. \n","\n","This will prompt the you to input a question, and then it will find chunks of text that might answer the question, and summarize the answer from those text chunks using GPT-3. To reference the text, you need to follow up with a question asking where the bot got the information from. I haven't found a super clean way to just automatically generate this.\n","\n","FYI - this step costs money"]},{"cell_type":"code","source":["ask_svb()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"JIrPJrInd33y","outputId":"68b4c0b1-7320-4858-c406-313541a98e2d"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? What exactly happened, step by step? A timeline of events.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\n1. KPMG signs an audit report giving SVB Financial, Silicon Valley Bank's parent company, a clean bill of health for 2022. \n2. SVB's deposits peak at the end of the first quarter of 2022 after surging 86% in 2021. \n3. The Federal Reserve begins raising interest rates. \n4. Venture capital dries up, leading startups to burn cash. \n5. To meet accelerating withdrawals, SVB is forced to sell off some of its government bonds at steep losses. \n6. Silicon Valley Bank announces it would book a $1.8 billion loss after selling.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? Was Garret Camp responsible for SVB meltdown?\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nNo, Garret Camp was not responsible for the SVB meltdown. The 2018 financial deregulation law, the Gallup poll from 2021, and the Fed raising rates all played a role in the meltdown.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? Was Garret Camp responsible for SVB meltdown?  I think he might be indirectly.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nIt is difficult to definitively answer this question without more information. Garret Camp is the founder of SVB, so it is possible that he could have been responsible for the meltdown in some way. However, it is also possible that the meltdown was caused by a combination of factors, such as the 2018 financial deregulation, the overheating of the economy, and the negative view of the tech industry. It is also possible that Camp had no direct involvement in the meltdown. Without more information, it is impossible to say for sure whether or not Camp was responsible for the SVB meltdown.</b>"},"metadata":{}}]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":925},"id":"Pk7Gt-Kg_1dH","outputId":"b597cfc3-2f42-41e8-dba1-b1d8c6102eeb","executionInfo":{"status":"error","timestamp":1679088149951,"user_tz":420,"elapsed":1497709,"user":{"displayName":"Manish Chablani","userId":"18122769995724977436"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? What exactly happened, step by step? A timeline of events.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\n1. KPMG signs an audit report giving SVB Financial, Silicon Valley Bank's parent company, a clean bill of health for 2022. \n2. SVB's deposits peak at the end of the first quarter of 2022 after surging 86% in 2021. \n3. The Federal Reserve begins raising interest rates. \n4. Venture capital dries up, leading startups to burn cash. \n5. To meet accelerating withdrawals, SVB is forced to sell off some of its government bonds at steep losses. \n6. Silicon Valley Bank announces it would book a $1.8 billion loss after selling.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? who triggered SVB meltdown\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nThe trigger for the SVB meltdown was clients trying to withdraw $42 billion on March 9.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? What was the role of fed in SVB meltdown? Could they have done something diffrent?\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nThe role of the Federal government in the SVB meltdown was to monitor the banking system for risk and to take action to prevent a bank run. However, the FDIC and OCC failed to do their jobs and a bank run ensued. The Federal government could have stepped in on Friday to guarantee SVB's deposits in exchange for penny warrants, which would have wiped out the majority of its equity value. This approach would have minimized the risk of any government losses and created the potential for substantial profits from the rescue.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? Was Garret Camp responsible for SVB meltdown?  I think he might be indirectly.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nIt is difficult to definitively answer this question without more information. Garret Camp is the founder of SVB, so it is possible that he could have been responsible for the meltdown in some way. However, it is also possible that the meltdown was caused by a combination of factors, such as the 2018 financial deregulation, the overheating of the economy, and the negative view of the tech industry. It is also possible that Camp had no direct involvement in the meltdown. Without more information, it is impossible to say for sure whether or not Camp was responsible for the SVB meltdown.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? When was SVB founded?\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nSVB was not mentioned in the context information, so it is not possible to answer the question with the given information.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? Who started SVB?\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nIt is unclear who started SVB.</b>"},"metadata":{}},{"name":"stdout","output_type":"stream","text":["What questions do you have about the SVB meltdown? Who is the CEO of SVB now?\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"SVB Bot says: <b>\nIt is unclear who the CEO of SVB is now.</b>"},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4308bf4cd52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_svb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-e075257324a9>\u001b[0m in \u001b[0;36mask_svb\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTSimpleVectorIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What questions do you have about the SVB meltdown? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SVB Bot says: <b>{response.response}</b>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["ask_svb()"]},{"cell_type":"code","source":[],"metadata":{"id":"BtGXdg4vXQbh"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1TBe7zSfWYrT6rx65Tn06aZALkXUc7BOi","timestamp":1679076396928},{"file_id":"1HL3f7fIWGQmZUt2zhsd8xb4ylhL_DqGU","timestamp":1678910222930},{"file_id":"1p2AablavDkSXly6H-XNLoSylMtoz7NDG","timestamp":1678688554329}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}